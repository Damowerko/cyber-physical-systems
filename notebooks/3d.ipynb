{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import typing\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from torchcps.kernel.nn import KNN, Mixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a datset using objects in 3D space\n",
    "n_simulations = 1000\n",
    "n_steps = 10\n",
    "n_sensors = 4\n",
    "n_dimensions = 3\n",
    "\n",
    "\n",
    "width = 1000  # width of the area where targets are placed\n",
    "min_height = 1000  # min height at which the targets are placed\n",
    "padding = 0.25\n",
    "vel_initial = 5.0\n",
    "vel_noise = 0.5\n",
    "\n",
    "# sensor parameters\n",
    "sensor_noise_range = 10\n",
    "sensor_noise_bearing = 0.035\n",
    "sensor_noise_inclination = 0.035"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nearly constant velocity model\n",
    "F_matrix = torch.tensor(\n",
    "    [\n",
    "        [1, 0, 0, 1, 0, 0],\n",
    "        [0, 1, 0, 0, 1, 0],\n",
    "        [0, 0, 1, 0, 0, 1],\n",
    "        [0, 0, 0, 1, 0, 0],\n",
    "        [0, 0, 0, 0, 1, 0],\n",
    "        [0, 0, 0, 0, 0, 1],\n",
    "    ]\n",
    ").float()\n",
    "G_matrix = torch.tensor(\n",
    "    [\n",
    "        [0.5, 0, 0],\n",
    "        [0, 0.5, 0],\n",
    "        [0, 0, 0.5],\n",
    "        [1, 0, 0],\n",
    "        [0, 1, 0],\n",
    "        [0, 0, 1],\n",
    "    ]\n",
    ").float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    ## create target trajectories\n",
    "    targets = torch.zeros(n_simulations, n_steps, 2 * n_dimensions)\n",
    "    # targets are placed uniformly in the area\n",
    "    targets[:, 0, 0].uniform_(-width / 2 + width * padding, width / 2 - width * padding)\n",
    "    targets[:, 0, 1].uniform_(-width / 2 + width * padding, width / 2 - width * padding)\n",
    "    targets[:, 0, 2].uniform_(\n",
    "        min_height + width * padding, min_height + width - width * padding\n",
    "    )\n",
    "    # initial velocity is constant but with random direction\n",
    "    targets[:, 0, 3:].normal_()\n",
    "    targets[:, 0, 3:] *= vel_initial * torch.norm(\n",
    "        targets[:, 0, 3:], dim=1, keepdim=True\n",
    "    )\n",
    "\n",
    "    for i in range(1, n_steps):\n",
    "        targets[:, i, :, None] = F_matrix @ targets[\n",
    "            :, i - 1, :, None\n",
    "        ] + G_matrix @ torch.normal(0, vel_noise, (n_simulations, 3, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5, 5))\n",
    "ax = fig.add_subplot(111, projection=\"3d\")\n",
    "ax = typing.cast(Axes3D, ax)\n",
    "\n",
    "ax.set_xlim(-width / 2, width / 2)\n",
    "ax.set_ylim(-width / 2, width / 2)\n",
    "ax.set_zlim(min_height, min_height + width)\n",
    "for i in range(10):\n",
    "    ax.plot(*targets[i, :, :].T)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    # sensors are placed on the ground at 0 height (z = 0)\n",
    "    sensors = torch.stack(\n",
    "        [\n",
    "            torch.empty(n_simulations, n_sensors).uniform_(-width / 2, width / 2),\n",
    "            torch.empty(n_simulations, n_sensors).uniform_(-width / 2, width / 2),\n",
    "            torch.zeros(n_simulations, n_sensors),\n",
    "        ],\n",
    "        dim=-1,\n",
    "    )\n",
    "\n",
    "    # relative position of targets to sensors\n",
    "    # shape: (n_simulations, n_steps, n_sensors, n_dimensions)\n",
    "    dx = targets[:, :, None, :3] - sensors[:, None, :, :]\n",
    "    r = torch.norm(dx, dim=-1)\n",
    "\n",
    "    # add noise in polar coordinates\n",
    "    measurements_range = (\n",
    "        r + torch.randn(n_simulations, n_steps, n_sensors) * sensor_noise_range\n",
    "    )\n",
    "    measurements_bearing = (\n",
    "        # theta = atan2(y / x)\n",
    "        torch.atan2(dx[..., 1], dx[..., 0])\n",
    "        + torch.randn(n_simulations, n_steps, n_sensors) * sensor_noise_bearing\n",
    "    )\n",
    "    measurements_elevation = (\n",
    "        # phi = acos(z / r)\n",
    "        torch.acos(dx[..., 2] / r)\n",
    "        + torch.randn(n_simulations, n_steps, n_sensors) * sensor_noise_inclination\n",
    "    )\n",
    "\n",
    "    # convert back to cartesian coordinates\n",
    "    # x = r cos(theta) sin(phi)\n",
    "    # y = r sin(theta) sin(phi)\n",
    "    # z = r cos(phi)\n",
    "    measurements = sensors[:, None, :, :] + torch.stack(\n",
    "        [\n",
    "            measurements_range\n",
    "            * torch.cos(measurements_bearing)\n",
    "            * torch.sin(measurements_elevation),\n",
    "            measurements_range\n",
    "            * torch.sin(measurements_bearing)\n",
    "            * torch.sin(measurements_elevation),\n",
    "            measurements_range * torch.cos(measurements_elevation),\n",
    "        ],\n",
    "        dim=-1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(measurements.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make an x-y plot of the target path, sensor positions and measurements for a specific simulation\n",
    "sim_idx = 0\n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "ax = fig.add_subplot(111, projection=\"3d\")\n",
    "ax = typing.cast(Axes3D, ax)\n",
    "ax.plot(*targets[sim_idx, :, :3].T, label=\"target\")\n",
    "# ax.scatter(*sensors[sim_idx, :, :].T, label=\"sensor\")\n",
    "ax.scatter(*measurements[sim_idx].reshape(-1, 3).T, label=\"measurement\", c=\"r\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNN(\n",
    "    n_dimensions=3,\n",
    "    # the time index of the measurements and sensor positions\n",
    "    in_channels=4,\n",
    "    hidden_channels=128,\n",
    "    # the position of the targets\n",
    "    out_channels=4,\n",
    "    n_layers=4,\n",
    "    n_layers_mlp=2,\n",
    "    hidden_channels_mlp=128,\n",
    "    sigma=50,\n",
    "    max_filter_kernels=256,\n",
    "    update_positions=True,\n",
    "    alpha=None,\n",
    ").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_logp(\n",
    "    mu: torch.Tensor,\n",
    "    sigmas: torch.Tensor,\n",
    "    existance_logp: torch.Tensor,\n",
    "    y: torch.Tensor,\n",
    ") -> torch.Tensor:\n",
    "    # \\sum_i p_i * gaussian(x | mu_i, sigma_i)\n",
    "    normal_logp = (\n",
    "        torch.distributions.Normal(mu, sigmas).log_prob(y_positions[:, None])\n",
    "        # product in linear space to get multivariate normal\n",
    "        .sum(-1)\n",
    "    )\n",
    "    # product in linear space to scale by probabilities\n",
    "    logp = normal_logp + existance_logp\n",
    "    # sum over all components and average over the batch\n",
    "    return logp.logsumexp(dim=(0, 1)) - math.log(y.shape[0])\n",
    "\n",
    "\n",
    "dataset = TensorDataset(\n",
    "    measurements.cuda(),\n",
    "    sensors[:, None].expand(measurements.shape).cuda(),\n",
    "    targets.cuda(),\n",
    ")\n",
    "dataloader = DataLoader(dataset, batch_size=10, shuffle=True, drop_last=True)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5, weight_decay=0.0)\n",
    "\n",
    "pbar = tqdm(range(100))\n",
    "log = []\n",
    "log_ema = None\n",
    "for epoch in pbar:\n",
    "    for x, s, y in dataloader:\n",
    "        B = x.shape[0]\n",
    "        x_positions = x.reshape(B * n_steps * n_sensors, n_dimensions)\n",
    "        # the weights encode the step index [0, n_steps - 1]\n",
    "        x_weights = torch.concatenate(\n",
    "            (\n",
    "                s,\n",
    "                torch.arange(n_steps, device=x.device)\n",
    "                .float()[None, :, None, None]\n",
    "                .expand(B, n_steps, n_sensors, 1),\n",
    "            ),\n",
    "            dim=-1,\n",
    "        ).reshape(B * n_steps * n_sensors, 4)\n",
    "\n",
    "        # the length of each batch is n_steps * n_sensors\n",
    "        x_batch = torch.full((B,), n_steps * n_sensors, device=x.device)\n",
    "        x_mixture = Mixture(x_positions, x_weights, x_batch)\n",
    "        z_mixture = model.forward(x_mixture)\n",
    "\n",
    "        # parse mixture\n",
    "        mu = z_mixture.positions.reshape(B, n_steps * n_sensors, 3)\n",
    "        sigmas = F.softplus(z_mixture.weights[:, :-1]).reshape(\n",
    "            B, n_steps * n_sensors, 3\n",
    "        )\n",
    "        # interpret as probabilities for each component within a batch\n",
    "        existance_logp = (\n",
    "            z_mixture.weights[:, -1].reshape(B, n_steps * n_sensors).log_softmax(-1)\n",
    "        )\n",
    "\n",
    "        # we want to predict the final position of the target\n",
    "        y_positions = y[:, -1, :3]\n",
    "\n",
    "        rmse = (\n",
    "            (y_positions - mu[:, existance_logp.argmax(-1)])\n",
    "            .pow(2)\n",
    "            .sum(-1)\n",
    "            .sqrt()\n",
    "            .mean()\n",
    "        )\n",
    "\n",
    "        # log-probability loss\n",
    "        value = compute_logp(mu, sigmas, existance_logp, y_positions)\n",
    "        loss = -value\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        # Check if any gradients are non-finite\n",
    "        if any(\n",
    "            torch.isinf(p.grad).any() or torch.isnan(p.grad).any()  # type: ignore\n",
    "            for p in model.parameters()\n",
    "            if p.grad is not None\n",
    "        ):\n",
    "            print(\"Warning: non-finite gradient detected. Skipping this iteration.\")\n",
    "            continue\n",
    "        optimizer.step()\n",
    "\n",
    "        log.append(\n",
    "            {\n",
    "                \"logp\": value.item(),\n",
    "                \"prob\": value.exp().item(),\n",
    "                \"rmse\": rmse.item(),\n",
    "                \"sigma\": sigmas.mean().item(),\n",
    "            }\n",
    "        )\n",
    "        if log_ema is None:\n",
    "            log_ema = log[-1]\n",
    "        else:\n",
    "            log_ema = {k: 0.9 * v + 0.1 * log[-1][k] for k, v in log_ema.items()}\n",
    "\n",
    "        pbar.set_postfix(log_ema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal.windows import gaussian\n",
    "\n",
    "metric = \"logp\"\n",
    "\n",
    "# gaussian window smoothing\n",
    "window_std = 100\n",
    "window = gaussian(window_std * 6, std=window_std)\n",
    "window /= window.sum()\n",
    "value = np.array([l[metric] for l in log])\n",
    "value_smooth = scipy.signal.convolve(value, window, mode=\"valid\")\n",
    "\n",
    "# plot metric over time\n",
    "plt.figure()\n",
    "plt.plot(value_smooth, label=metric)\n",
    "plt.legend()\n",
    "plt.xlabel(\"step\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
