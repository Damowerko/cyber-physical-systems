{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a datset of 2D signals with noise\n",
    "n_samples = 10_000\n",
    "n_sensors = 4\n",
    "n_measurements = 5\n",
    "n_dimensions = 2\n",
    "width = 1000\n",
    "\n",
    "noise_range = 10\n",
    "noise_bearing = 0.1\n",
    "\n",
    "n_output_positions = 10\n",
    "noise_output = 10.0\n",
    "\n",
    "with torch.no_grad():\n",
    "    targets = width / 2 * torch.rand(n_samples, n_dimensions) - width / 4\n",
    "    sensors = width / 2 * torch.rand(n_samples, n_sensors, n_dimensions) / 2\n",
    "\n",
    "    # relative position of targets to sensors\n",
    "    dx = targets[:, None] - sensors\n",
    "    dx = dx[..., None, :]\n",
    "    # add noise in polar coordinates\n",
    "    measurements_range = (\n",
    "        torch.norm(dx, dim=-1)\n",
    "        + torch.randn(n_samples, n_sensors, n_measurements) * noise_range\n",
    "    )\n",
    "    measurements_bearing = (\n",
    "        torch.atan2(dx[..., 1], dx[..., 0])\n",
    "        + torch.randn(n_samples, n_sensors, n_measurements) * noise_bearing\n",
    "    )\n",
    "    # convert back to cartesian coordinates\n",
    "    measurements = sensors[..., None, :] + torch.stack(\n",
    "        [\n",
    "            measurements_range * torch.cos(measurements_bearing),\n",
    "            measurements_range * torch.sin(measurements_bearing),\n",
    "        ],\n",
    "        dim=-1,\n",
    "    )\n",
    "    # combine the n_sensors and n_measurements dimensions\n",
    "    measurements = measurements.reshape(\n",
    "        n_samples, n_sensors * n_measurements, n_dimensions\n",
    "    )\n",
    "    targets = targets[:, None, None, :]\n",
    "    measurements = measurements[:, None, :, :]\n",
    "\n",
    "    # add noise to the measurements, to get the sampling points for the output\n",
    "    output_positions = noise_output * torch.randn(\n",
    "        n_samples, n_output_positions, n_sensors * n_measurements, n_dimensions\n",
    "    )\n",
    "    output_positions = (output_positions + measurements).reshape(\n",
    "        n_samples, 1, n_output_positions * n_sensors * n_measurements, n_dimensions\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate naive strategy of taking mean of measurements\n",
    "input_mean = measurements.mean(2, True)\n",
    "(input_mean - targets).abs().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the distribution of measurements and targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for i in range(10):\n",
    "    idx = np.random.randint(0, n_samples)\n",
    "    plt.plot(*targets[idx, 0, 0].numpy(), f\"C{i}x\", markersize=10)\n",
    "    plt.plot(*measurements[idx, 0].T.numpy(), f\"C{i}.\", markersize=5)\n",
    "    plt.plot(*output_positions[idx, 0].T.numpy(), f\"k.\", markersize=1, alpha=0.05)\n",
    "    plt.xlim(-width / 2, width / 2)\n",
    "    plt.ylim(-width / 2, width / 2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torchcps.kernel.rkhs import GaussianKernel\n",
    "from torchcps.kernel.nn import (\n",
    "    KernelConv,\n",
    "    KernelMap,\n",
    "    KernelNorm,\n",
    "    KernelSample,\n",
    "    Mixture,\n",
    ")\n",
    "\n",
    "max_filter_kernels = 128\n",
    "n_channels = 1\n",
    "n_weights = 32\n",
    "in_weights = 1\n",
    "out_weights = 1\n",
    "update_positions = False\n",
    "\n",
    "sigma = [5.0] * 3\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        self.n_layers = len(sigma)\n",
    "        self.nonlinearity = KernelMap(nn.LeakyReLU())\n",
    "        self.readin = KernelMap(nn.Linear(in_weights, n_weights))\n",
    "        self.readout = KernelMap(nn.Linear(n_weights, out_weights))\n",
    "\n",
    "        conv_layers = []\n",
    "        norm_layers = []\n",
    "        linear_layers = []\n",
    "        sample_layers = []\n",
    "        for l in range(self.n_layers):\n",
    "            first_layer = l == 0\n",
    "            last_layer = l == self.n_layers - 1\n",
    "            conv_layers += [\n",
    "                KernelConv(\n",
    "                    max_filter_kernels=max_filter_kernels,\n",
    "                    in_channels=1 if first_layer else n_channels,\n",
    "                    out_channels=1 if last_layer else n_channels,\n",
    "                    n_dimensions=2,\n",
    "                    kernel_spread=3 * sigma[l] * max_filter_kernels**0.5,\n",
    "                    n_weights=n_weights,\n",
    "                    update_positions=update_positions,\n",
    "                    kernel_init=\"uniform\",\n",
    "                )\n",
    "            ]\n",
    "            linear_layers += [KernelMap(nn.Linear(n_weights, n_weights))]\n",
    "            norm_layers += [KernelNorm(1 if last_layer else n_channels, n_weights)]\n",
    "            sample_layers += [\n",
    "                KernelSample(\n",
    "                    kernel=GaussianKernel(sigma[l]),\n",
    "                    alpha=None,\n",
    "                    nonlinearity=nn.LeakyReLU(),\n",
    "                )\n",
    "            ]\n",
    "\n",
    "        self.conv_layers = nn.ModuleList(conv_layers)\n",
    "        self.norm_layers = nn.ModuleList(norm_layers)\n",
    "        self.linear_layers = nn.ModuleList(linear_layers)\n",
    "        self.sample_layers = nn.ModuleList(sample_layers)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input: Mixture,\n",
    "        output_positions: torch.Tensor,\n",
    "    ):\n",
    "        input_positions = input.positions.expand(-1, n_channels, -1, -1).contiguous()\n",
    "        x: Mixture = self.readin(input)\n",
    "        # x = self.nonlinearity(x)\n",
    "        for l in range(self.n_layers):\n",
    "            h = x.weights\n",
    "            x = self.conv_layers[l](x)\n",
    "            # sample on input positions for all layers except the last\n",
    "            x = Mixture(x.positions.contiguous(), x.weights.contiguous())\n",
    "            x = self.sample_layers[l](x, output_positions)\n",
    "            x = self.linear_layers[l](x)\n",
    "            # x = self.norm_layers[l](x)\n",
    "            x = self.nonlinearity(x)\n",
    "            # residual connection\n",
    "            if l > 0:\n",
    "                x = Mixture(x.positions, x.weights + h)\n",
    "\n",
    "        x = self.readout(x)\n",
    "        x = self.nonlinearity(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "dataset = TensorDataset(measurements.cuda(), targets.cuda(), output_positions.cuda())\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, drop_last=True)\n",
    "model = Model().cuda()\n",
    "\n",
    "\n",
    "# positions should not be regularized\n",
    "parameters = list(model.named_parameters())\n",
    "positions = [p for n, p in parameters if \"_positions\" in n]\n",
    "weights = [p for n, p in parameters if \"_positions\" not in n]\n",
    "optimizer = AdamW(\n",
    "    [\n",
    "        dict(params=weights, lr=1e-2, weight_decay=0.0),\n",
    "        dict(params=positions, lr=1e-5, weight_decay=0.0),\n",
    "    ],\n",
    ")\n",
    "# lr scheduling\n",
    "scheduler = ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode=\"min\",\n",
    "    factor=0.1,\n",
    "    patience=2,\n",
    ")\n",
    "\n",
    "mse_values = []\n",
    "x_weights, y_weights = None, None\n",
    "for i in range(20):\n",
    "    pbar = tqdm(dataloader, total=len(dataloader))\n",
    "    total_mse = 0.0\n",
    "    for i, (x, y, z_pos) in enumerate(pbar):\n",
    "        x_weights = torch.ones(*x.shape[:-1], device=\"cuda\", requires_grad=False)[\n",
    "            ..., None\n",
    "        ]\n",
    "        y_weights = torch.ones(*y.shape[:-1], device=\"cuda\", requires_grad=False)[\n",
    "            ..., None\n",
    "        ]\n",
    "        (z, z_weights) = model.forward(Mixture(x, x_weights), z_pos)\n",
    "\n",
    "        mse = (\n",
    "            GaussianKernel(sigma[-1])\n",
    "            .squared_error(y, y_weights, z, z_weights)\n",
    "            .mean(0)\n",
    "            .sum()\n",
    "        )\n",
    "        total_mse += mse.item()\n",
    "        mse_values.append(mse.detach().item())\n",
    "\n",
    "        pbar.set_postfix(\n",
    "            iter_mse=mse.item(),\n",
    "            epoch_mse=total_mse / (i + 1),\n",
    "            lr=optimizer.param_groups[0][\"lr\"],\n",
    "        )\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        mse.backward()\n",
    "        optimizer.step()\n",
    "    scheduler.step(total_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(mse_values[-10:]))\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(mse_values, label=\"MSE\")\n",
    "plt.legend()\n",
    "plt.ylim(0, 2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def raster_rkhs(X: Mixture, sigma: float, width: float, resolution: int, relu=False):\n",
    "    XY = (\n",
    "        torch.stack(\n",
    "            torch.meshgrid(\n",
    "                torch.linspace(-width / 2, width / 2, resolution),\n",
    "                torch.linspace(-width / 2, width / 2, resolution),\n",
    "            ),\n",
    "            dim=-1,\n",
    "        )\n",
    "        .reshape(-1, 2)\n",
    "        .to(X.positions.device)\n",
    "    )\n",
    "    kernel = GaussianKernel(sigma)\n",
    "    values = kernel(XY, X.positions[0, 0]) @ X.weights\n",
    "    XY = XY.reshape(resolution, resolution, 2).detach()\n",
    "    values = values.reshape(resolution, resolution).detach()\n",
    "    return values, XY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test = 100\n",
    "indices = np.random.choice(n_samples, n_test, replace=False)\n",
    "\n",
    "model.eval()\n",
    "mae_mean = 0\n",
    "mae_mode = 0\n",
    "with torch.no_grad():\n",
    "    for idx in tqdm(indices):\n",
    "        x = measurements[None, idx, ...].cuda()\n",
    "        y = targets[None, idx, None, :].cuda()\n",
    "        out = output_positions[None, idx, ...].cuda()\n",
    "        x_weights = torch.ones(*x.shape[:-1], device=x.device)[..., None]\n",
    "        y_weights = torch.ones(*y.shape[:-1], device=y.device)[..., None]\n",
    "\n",
    "        Z = model(Mixture(x, x_weights), out)\n",
    "\n",
    "        # output argmax\n",
    "        values, XY = raster_rkhs(Z, sigma[-1], width, 1000)\n",
    "        # values.relu_()\n",
    "        # expectation\n",
    "        mean_xy = (XY * values[..., None]).sum((0, 1)) / values.sum()\n",
    "        mae_mean += ((mean_xy - y.squeeze()).abs()).sum() / n_test\n",
    "        # mode\n",
    "        mode_xy = XY.reshape(-1, 2)[torch.argmax(values)]\n",
    "        mae_mode += ((mode_xy - y.squeeze()).abs()).sum() / n_test\n",
    "print(f\"Mean Absolute Error (MEAN): {mae_mean.item():.2f}\")\n",
    "print(f\"Mean Absolute Error (MODE): {mae_mode.item():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.randint(0, n_samples)\n",
    "resolution = 2000\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    x = measurements[None, idx, ...].cuda()\n",
    "    y = targets[None, idx, None, :].cuda()\n",
    "    x_weights = torch.ones(*x.shape[:-1], device=x.device)[..., None]\n",
    "    y_weights = torch.ones(*y.shape[:-1], device=y.device)[..., None]\n",
    "    out = output_positions[None, idx, ...].cuda()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        z, z_weights = model(Mixture(x, x_weights), out)\n",
    "    model.train()\n",
    "\n",
    "    # squeeze all the tensors\n",
    "    x = x.squeeze().cpu()\n",
    "    y = y.squeeze().cpu()\n",
    "\n",
    "    extent = [-width / 2, width / 2, -width / 2, width / 2]\n",
    "    values, XY = raster_rkhs(Mixture(z, z_weights), sigma[-1], width, resolution)\n",
    "    # values = values.relu()\n",
    "    # naive way to make predictions\n",
    "    input_mean = x.mean(0)\n",
    "    # expectation\n",
    "    mean_xy = (XY * values[..., None]).sum((0, 1))\n",
    "    # mode\n",
    "    mode_xy = XY.reshape(-1, 2)[torch.argmax(values)]\n",
    "\n",
    "    # get the intensity value at the target position\n",
    "    target_value = GaussianKernel(sigma[-1])(y[None, None, None, :].cuda(), z)\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(values.T.cpu().detach(), extent=extent, origin=\"lower\")\n",
    "\n",
    "plt.plot(*x.T, \".\", label=\"Measurements\")\n",
    "plt.plot(*y, \"x\", label=\"Target\")\n",
    "plt.plot(*input_mean, \"o\", label=\"Mean of Measurements\")\n",
    "plt.plot(*mean_xy.detach().cpu(), \"o\", label=\"Mean of CNN output\")\n",
    "plt.plot(*mode_xy.detach().cpu(), \"o\", label=\"Mode of CNN output\")\n",
    "\n",
    "# plt.xlim(extent[0], extent[1])\n",
    "# plt.ylim(extent[2], extent[3])\n",
    "# axis limits y +- w\n",
    "w = 100\n",
    "plt.xlim(y[0] - w, y[0] + w)\n",
    "plt.ylim(y[1] - w, y[1] + w)\n",
    "\n",
    "plt.legend()\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def raster_filter(\n",
    "    X: Mixture,\n",
    "    sigma: float,\n",
    "    weight_idx: int,\n",
    "    channel: tuple[int, int],\n",
    "    width: float,\n",
    "    resolution: int,\n",
    "):\n",
    "    X_ = Mixture(\n",
    "        X.positions[channel[0], channel[1], None, None, ...],\n",
    "        X.weights[channel[0], channel[1], None, None, :, weight_idx, None].contiguous(),\n",
    "    )\n",
    "    return raster_rkhs(X_, sigma, width, resolution)[0].detach().cpu()\n",
    "\n",
    "\n",
    "# Plot the CNN Filter at the lth layer\n",
    "l = 0\n",
    "channel = (0, 0)\n",
    "\n",
    "\n",
    "conv_layers = model.conv_layers\n",
    "positions = conv_layers[l].kernel_positions\n",
    "weights = conv_layers[l].kernel_weights\n",
    "assert isinstance(positions, torch.Tensor) and isinstance(weights, torch.Tensor)\n",
    "\n",
    "n_weights = weights.shape[3]\n",
    "fig, axs = plt.subplots(\n",
    "    1,\n",
    "    n_weights,\n",
    "    figsize=(n_weights, 1),\n",
    "    sharex=True,\n",
    "    sharey=True,\n",
    ")\n",
    "for i in range(n_weights):\n",
    "    rkhs = Mixture(positions, weights)\n",
    "    filter_width = sigma[l] * 10\n",
    "    extent = np.array([-1, 1, -1, 1]) * filter_width / 2\n",
    "\n",
    "    if n_weights > 1:\n",
    "        ax = axs[i]\n",
    "    else:\n",
    "        ax = axs\n",
    "\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "    ax.imshow(\n",
    "        raster_filter(rkhs, sigma[l], i, channel, width=filter_width, resolution=32),\n",
    "        extent=extent,\n",
    "        origin=\"lower\",\n",
    "    )\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
